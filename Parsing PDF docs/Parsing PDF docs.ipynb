{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "g6s6ndcvn6ivbvgielye",
   "authorId": "7634164163803",
   "authorName": "HHVV",
   "authorEmail": "vietha.le92@gmail.com",
   "sessionId": "86c6c53e-a413-4f2e-aa15-28442fb62c81",
   "lastEditTime": 1763808163118
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e6654b-a4f4-41cf-af78-8a5970282187",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# PDF extraction\n## Option 1: Process all JPEG files in stage using AI_PARSE_DOCUMENT\n### Step 1: Load files into stage\n\n\n"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_packages"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\n# Import required libraries\nimport snowflake.connector\nimport re\nimport time\n\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cf8b2136-ad34-40f0-b6b9-1da7fec4520f",
   "metadata": {
    "language": "sql",
    "name": "put_local_to_internal_stage"
   },
   "outputs": [],
   "source": "-- This step needs to be done from local machine\n-- The stage must follow this guide:",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "898d97f1-76fc-46a0-a99c-6ec6d857536e",
   "metadata": {
    "language": "python",
    "name": "create_file_list"
   },
   "outputs": [],
   "source": "if session.sql('select * from raw.pdf.file_list') is None:\n\n    session.sql(f'''\n    CREATE OR REPLACE TABLE raw.pdf.file_list as\n    SELECT distinct        \n        metadata$filename as file_name,\n        metadata$file_last_modified as file_last_modified,\n        split_part(file_name, '_',1) as from_where,\n        split_part(split_part(file_name, '/',2),'.',1) as table_name\n    FROM @RAW.PDF.BNK\n    where metadata$filename ilike '%jpeg'\n    ''')\n\nfile_list = session.sql('select * from raw.pdf.file_list').to_pandas()\nfile_list\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39f370d2-bf5c-4c7d-8312-0190b1d813d9",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "### Step 2: Parse everything into tables"
  },
  {
   "cell_type": "code",
   "id": "d64c97e5-b25d-448b-a439-3f83c152648b",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# process_count = 0\n# total_files = len(file_list)\n\nfor x in file_list.iterrows():\n    file_name = x[1]['FILE_NAME']\n    table_name = x[1]['TABLE_NAME']\n    print(file_name, table_name)\n    parse_query = f\"\"\"\n        create or replace table RAW.PDF.{table_name} as (\n        SELECT AI_PARSE_DOCUMENT (\n            TO_FILE('@\"RAW\".\"PDF\".\"BNK\"','{file_name}'),\n            {{'mode': 'LAYOUT', 'page_split': false}}) AS content);\n            \"\"\"\n    session.sql(parse_query).collect()\n    session.sql(f\"select * from RAW.PDF.{table_name}\").collect()\n\nprint(\"Completed loading to tables\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62d109e2-82d4-4d1f-8b7d-dad5ff523b2c",
   "metadata": {
    "language": "python",
    "name": "union_to_one",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "process_count = 0\ntotal_files = len(file_list)\nprint(total_files)\nquery = \"\"\n\n\nfor x in file_list.iterrows():\n    table_name = x[1]['TABLE_NAME']\n    \n    process_count +=1\n    if process_count < total_files:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content from RAW.PDF.{table_name} union all  --{process_count}\n        \"\"\"\n    else:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content from RAW.PDF.{table_name}  --{process_count}\n        \"\"\"\n\nprint(query)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c2bcdf5-e359-4b7b-b74c-0db6c14819ba",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "\n    create database transform;\n    create schema transform.intermediate;\n    -- create table transform.intermediate.unioned_pdf as         ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d92bc80c-88d4-4988-aff4-a0a05e1438b3",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "session.sql(f\"\"\"\n    create or replace table transform.intermediate.unioned_pdf as \n    (with unioned as ({query})\n    \n    select u.*,\n        fl.from_where\n    from unioned as u\n    left join raw.pdf.file_list as fl\n        on u.file_source = fl.table_name)\n\"\"\")\n# print(query)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f35ba91-bec0-4ad6-b1d4-b2f51f0070e5",
   "metadata": {
    "language": "sql",
    "name": "check_result_unioned"
   },
   "outputs": [],
   "source": "select * from transform.intermediate.unioned_pdf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc6021e1-8515-47a1-9281-0e3c4dfd9047",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "### Step 3: Create BankA table out of PDFs"
  },
  {
   "cell_type": "code",
   "id": "f376490e-5340-4061-968c-f3ce2bd2837b",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "create or replace table transform.intermediate.statements_bank_a as (\nwith joined as (\n    select *\n    from transform.intermediate.unioned_pdf\n    where from_where ilike '%bank_a%'\n),\ncleansed as (\n    select\n        from_where,\n        file_source,\n        index,\n        mod(index - 1, 11) as position_in_group,\n        value,\n        row_number() over(partition by file_source, position_in_group order by index) as record_group\n    from joined,\n    lateral split_to_table(content['content']::string,'|')\n    order by file_source,index \n),\n-- select * from cleansed;\ntransformed_data AS (\n    SELECT \n        file_source,\n        record_group,\n        MAX(CASE WHEN position_in_group = 1 THEN trim(value) END) AS transaction_date,\n        MAX(CASE WHEN position_in_group = 2 THEN trim(value) END) AS remitter,\n        MAX(CASE WHEN position_in_group = 3 THEN trim(value) END) AS remitter_bank,\n        MAX(CASE WHEN position_in_group = 4 THEN trim(value) END) AS details,\n        MAX(CASE WHEN position_in_group = 5 THEN trim(value) END) AS transaction_no,\n        MAX(CASE WHEN position_in_group = 6 THEN trim(value) END) AS debit,\n        MAX(CASE WHEN position_in_group = 7 THEN trim(value) END) AS credit,\n        MAX(CASE WHEN position_in_group = 8 THEN trim(value) END) AS fee_interest,\n        MAX(CASE WHEN position_in_group = 9 THEN trim(value) END) AS tax,\n        MAX(CASE WHEN position_in_group = 10 THEN trim(value) END) AS balance\n    from cleansed\n    group by all\n    having len(transaction_date) = 10\n    \n)\n-- select * from transformed_data order by file_source, record_group ;\n\nselect \n    file_source,\n    to_date(transaction_date, 'dd/mm/yyyy') AS transaction_date,\n    remitter,\n    remitter_bank,\n    details,\n    transaction_no,\n    TRY_CAST(REPLACE(debit, ',', '') AS DECIMAL(18,2)) AS debit,\n    TRY_CAST(REPLACE(credit, ',', '') AS DECIMAL(18,2)) AS credit,\n    TRY_CAST(REPLACE(fee_interest, ',', '') AS DECIMAL(18,2)) AS fee_interest,\n    TRY_CAST(REPLACE(tax, ',', '') AS DECIMAL(18,2)) AS tax,\n    TRY_CAST(REPLACE(balance, ',', '') AS DECIMAL(18,2)) AS balance,\n    row_number() over(order by file_source,record_group) AS record_sequence\nfrom transformed_data \norder by file_source, record_group \n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0f897ae3-ddc5-4326-99b0-7f5fb899ce6b",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Option 2: Process all JPEG files in stage using DOCUMENT AI\n### Step 1: Set up new db, schema, roles for Document AI\n"
  },
  {
   "cell_type": "code",
   "id": "c9448c5f-be04-4c12-b00f-76d25fd124a9",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "-- Set up new db and schema and roles for Document AI\nCREATE DATABASE doc_ai_db;\nCREATE SCHEMA doc_ai_db.doc_ai_schema;\n\nUSE ROLE ACCOUNTADMIN;\n\nCREATE ROLE doc_ai_role;\n\nGRANT DATABASE ROLE SNOWFLAKE.DOCUMENT_INTELLIGENCE_CREATOR TO ROLE doc_ai_role;\nGRANT USAGE, OPERATE ON WAREHOUSE COMPUTE_WH TO ROLE doc_ai_role;\nGRANT USAGE ON DATABASE doc_ai_db TO ROLE doc_ai_role;\nGRANT USAGE ON SCHEMA doc_ai_db.doc_ai_schema TO ROLE doc_ai_role;\nGRANT CREATE STAGE ON SCHEMA doc_ai_db.doc_ai_schema TO ROLE doc_ai_role;\nGRANT CREATE SNOWFLAKE.ML.DOCUMENT_INTELLIGENCE ON SCHEMA doc_ai_db.doc_ai_schema TO ROLE doc_ai_role;\nGRANT CREATE MODEL ON SCHEMA doc_ai_db.doc_ai_schema TO ROLE doc_ai_role;\nGRANT CREATE STREAM, CREATE TABLE, CREATE TASK, CREATE VIEW ON SCHEMA doc_ai_db.doc_ai_schema TO ROLE doc_ai_role;\nGRANT EXECUTE TASK ON ACCOUNT TO ROLE doc_ai_role;\nGRANT ROLE doc_ai_role TO USER <user_name>;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85596c92-e8d8-4ef0-b948-e3e431d4738f",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "### Step 2: Create new staging for the files"
  },
  {
   "cell_type": "code",
   "id": "2192dfc8-3b50-4e58-aeeb-1a865e7f8c9f",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "\nuse role doc_ai_role;\nuse database doc_ai_db;\nuse schema doc_ai_schema;\n\n-- create document processing stage\nCREATE OR REPLACE STAGE my_pdf_stage\n  DIRECTORY = (ENABLE = TRUE)\n  ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE');\n\n-- create stream on stage\nCREATE OR REPLACE STREAM my_pdf_stream ON STAGE my_pdf_stage;\nALTER STAGE my_pdf_stage REFRESH;\n\n-- create pdf_reviews to store information about docs\nCREATE OR REPLACE TABLE pdf_reviews (\n  file_name VARCHAR,\n  file_size VARIANT,\n  last_modified VARCHAR,\n  snowflake_file_url VARCHAR,\n  json_content VARCHAR\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "107e420b-131d-4b1d-a9a4-9c3d73b56a2b",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "### Step 3: Train documents in Document AI\n- Use the doc_ai_role just created for these steps\n- Build a Document AI model\n- Upload sample files into Document (choose Table extraction)\n- Enter key, column names, then click Extract\n- Validate the tables extracted\n- Go to the build and Publish if satisfactory\n\nAfter this step is done you can try out the model on new documents uploaded onto your stage\n"
  },
  {
   "cell_type": "code",
   "id": "6218d7fc-26d2-4c9f-8ed8-7a7d992a5f10",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "\n---testing on 1 single file\nSELECT DOC_AI_DB.DOC_AI_SCHEMA.BANK_PDF_TABLE!PREDICT(\n  GET_PRESIGNED_URL('@my_pdf_stage', 'IMG_5281.jpeg'), 1);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ffa49331-0f77-47f7-9a64-c39e0e46a852",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "### Step 4: Apply the Document AI model onto all files"
  },
  {
   "cell_type": "code",
   "id": "ec951463-130b-42eb-9534-d58f5ad70f38",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": "-- Storing the extraction result into pdf_reviews table\nCREATE OR REPLACE TABLE pdf_reviews AS (\n  SELECT\n    RELATIVE_PATH AS file_name,\n    size AS file_size,\n    last_modified,\n    file_url AS snowflake_file_url,\n    BANK_PDF_TABLE!PREDICT(GET_PRESIGNED_URL('@my_pdf_stage', RELATIVE_PATH), 1) AS json_content\n  FROM my_pdf_stream\n  WHERE METADATA$ACTION = 'INSERT'\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd3f4990-81b7-4f6e-9188-c2f42b7c37a0",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": "create or replace table pdf_result as (\n--flatten json to column-based rows\nwith base as (\n    select \n        file_name,\n        json_content,\n        content.*\n    from pdf_reviews,\n    lateral flatten(input => json_content) as content\n    -- where file_name = 'IMG_5281.jpeg'\n),\n--flatten next to column-record-based rows\nstaging as (\n    select \n        base.file_name,\n        v.seq as column_ordinal,\n        lower(replace(replace(base.key,'transaction|',''),' ','_')) as column_name,\n        coalesce(base.value['ocrScore'], v.value['score'])::float as ocr_score,\n        v.value['value']::string as value,\n        v.index as _row_number\n    from base,\n    lateral flatten(input => value) as v\n),\n-- select * from staging;\nmeta_data as (\n    select\n        file_name,\n        case when column_name = '__documentmetadata' then ocr_score end as ocr_score_on_file,\n    from staging\n    where _row_number is null\n),\n-- select * from meta_data;\npivoted as (\n    select \n        staging.file_name,\n        _row_number,\n        meta_data.ocr_score_on_file,\n        max(case when column_name = 'sequence_no' then value end)as seq_no,\n        max(case when column_name = 'transaction_code' then value end)as txn_code,\n        -- max(case when column_name = 'cheque_no' then value end)as cheque_no, --has no value\n        max(case when column_name = 'transaction_date' then value end)as txn_date,\n        max(case when column_name = 'effective_date' then value end)as effective_date,\n        max(case when column_name = 'withdrawal' then value end)as withdrawal,\n        max(case when column_name = 'deposit' then value end)as deposit,\n        max(case when column_name = 'balance' then value end)as balance,\n        max(case when column_name = 'remarks' then value end)as remarks\n    \n    from staging\n    left join meta_data on staging.file_name = meta_data.file_name\n    where _row_number is not null\n    group by all\n    \n)\nselect\n    file_name,\n    _row_number,\n    ocr_score_on_file,\n    seq_no,\n    txn_code,\n    try_to_date(txn_date, 'dd/mm/yyyy') as txn_date,\n    try_to_date(effective_date, 'dd/mm/yyyy') as effective_date,\n    TRY_CAST(REPLACE(withdrawal, ',', '') AS DECIMAL(18,2)) AS withdrawal,\n    TRY_CAST(REPLACE(deposit, ',', '') AS DECIMAL(18,2)) AS deposit,\n    TRY_CAST(REPLACE(balance, ',', '') AS DECIMAL(18,2)) AS balance,\n    remarks\nfrom pivoted\norder by file_name, _row_number\n)",
   "execution_count": null
  }
 ]
}