{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "l74gewems7cgnwk2p3ah",
   "authorId": "7634164163803",
   "authorName": "HHVV",
   "authorEmail": "vietha.le92@gmail.com",
   "sessionId": "8026da00-1ef4-4fc0-abfd-43bbd9e9b97d",
   "lastEditTime": 1763289561596
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e6654b-a4f4-41cf-af78-8a5970282187",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# PDF extraction\n## Option 1: Process all JPEG files in stage using AI_PARSE_DOCUMENT\n### Step 1: Load files into stage\n\n\n"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_packages"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\n# Import required libraries\nimport snowflake.connector\nimport re\nimport time\n\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cf8b2136-ad34-40f0-b6b9-1da7fec4520f",
   "metadata": {
    "language": "sql",
    "name": "put_local_to_internal_stage"
   },
   "outputs": [],
   "source": "-- This step needs to be done from local machine\n-- The stage must follow this guide:",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "898d97f1-76fc-46a0-a99c-6ec6d857536e",
   "metadata": {
    "language": "python",
    "name": "create_file_list"
   },
   "outputs": [],
   "source": "if session.sql('select * from raw.pdf.file_list') is None:\n\n    session.sql(f'''\n    CREATE OR REPLACE TABLE raw.pdf.file_list as\n    SELECT distinct        \n        metadata$filename as file_name,\n        metadata$file_last_modified as file_last_modified,\n        split_part(file_name, '_',1) as from_where,\n        split_part(split_part(file_name, '/',2),'.',1) as table_name\n    FROM @RAW.PDF.BNK\n    where metadata$filename ilike '%jpeg'\n    ''')\n\nfile_list = session.sql('select * from raw.pdf.file_list').to_pandas()\nfile_list\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39f370d2-bf5c-4c7d-8312-0190b1d813d9",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "### Step 2: Parse everything into tables"
  },
  {
   "cell_type": "code",
   "id": "d64c97e5-b25d-448b-a439-3f83c152648b",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# process_count = 0\n# total_files = len(file_list)\n\nfor x in file_list.iterrows():\n    file_name = x[1]['FILE_NAME']\n    table_name = x[1]['TABLE_NAME']\n    print(file_name, table_name)\n    parse_query = f\"\"\"\n        create or replace table RAW.PDF.{table_name} as (\n        SELECT AI_PARSE_DOCUMENT (\n            TO_FILE('@\"RAW\".\"PDF\".\"BNK\"','{file_name}'),\n            {{'mode': 'LAYOUT', 'page_split': false}}) AS content);\n            \"\"\"\n    session.sql(parse_query).collect()\n    session.sql(f\"select * from RAW.PDF.{table_name}\").collect()\n\nprint(\"Completed loading to tables\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62d109e2-82d4-4d1f-8b7d-dad5ff523b2c",
   "metadata": {
    "language": "python",
    "name": "union_to_one",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "process_count = 0\ntotal_files = len(file_list)\nprint(total_files)\nquery = \"\"\n\n\nfor x in file_list.iterrows():\n    table_name = x[1]['TABLE_NAME']\n    \n    process_count +=1\n    if process_count < total_files:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content from RAW.PDF.{table_name} union all  --{process_count}\n        \"\"\"\n    else:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content from RAW.PDF.{table_name}  --{process_count}\n        \"\"\"\n\nprint(query)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c2bcdf5-e359-4b7b-b74c-0db6c14819ba",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "\n    create database transform;\n    create schema transform.intermediate;\n    -- create table transform.intermediate.unioned_pdf as         ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d92bc80c-88d4-4988-aff4-a0a05e1438b3",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "session.sql(f\"\"\"\n    create or replace table transform.intermediate.unioned_pdf as \n    (with unioned as ({query})\n    \n    select u.*,\n        fl.from_where\n    from unioned as u\n    left join raw.pdf.file_list as fl\n        on u.file_source = fl.table_name)\n\"\"\")\n# print(query)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f35ba91-bec0-4ad6-b1d4-b2f51f0070e5",
   "metadata": {
    "language": "sql",
    "name": "check_result_unioned"
   },
   "outputs": [],
   "source": "select * from transform.intermediate.unioned_pdf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc6021e1-8515-47a1-9281-0e3c4dfd9047",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "### Create TCB table out of PDFs"
  },
  {
   "cell_type": "code",
   "id": "f376490e-5340-4061-968c-f3ce2bd2837b",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "create or replace table transform.intermediate.statements_tcb as (\nwith joined as (\n    select *\n    from transform.intermediate.unioned_pdf\n    where from_where ilike '%tcb%'\n),\ncleansed as (\n    select\n        from_where,\n        file_source,\n        index,\n        mod(index - 1, 11) as position_in_group,\n        value,\n        row_number() over(partition by file_source, position_in_group order by index) as record_group\n    from joined,\n    lateral split_to_table(content['content']::string,'|')\n    order by file_source,index \n),\n-- select * from cleansed;\ntransformed_data AS (\n    SELECT \n        file_source,\n        record_group,\n        MAX(CASE WHEN position_in_group = 1 THEN trim(value) END) AS transaction_date,\n        MAX(CASE WHEN position_in_group = 2 THEN trim(value) END) AS remitter,\n        MAX(CASE WHEN position_in_group = 3 THEN trim(value) END) AS remitter_bank,\n        MAX(CASE WHEN position_in_group = 4 THEN trim(value) END) AS details,\n        MAX(CASE WHEN position_in_group = 5 THEN trim(value) END) AS transaction_no,\n        MAX(CASE WHEN position_in_group = 6 THEN trim(value) END) AS debit,\n        MAX(CASE WHEN position_in_group = 7 THEN trim(value) END) AS credit,\n        MAX(CASE WHEN position_in_group = 8 THEN trim(value) END) AS fee_interest,\n        MAX(CASE WHEN position_in_group = 9 THEN trim(value) END) AS tax,\n        MAX(CASE WHEN position_in_group = 10 THEN trim(value) END) AS balance\n    from cleansed\n    group by all\n    having len(transaction_date) = 10\n    \n)\n-- select * from transformed_data order by file_source, record_group ;\n\nselect \n    file_source,\n    to_date(transaction_date, 'dd/mm/yyyy') AS transaction_date,\n    remitter,\n    remitter_bank,\n    details,\n    transaction_no,\n    TRY_CAST(REPLACE(debit, ',', '') AS DECIMAL(18,2)) AS debit,\n    TRY_CAST(REPLACE(credit, ',', '') AS DECIMAL(18,2)) AS credit,\n    TRY_CAST(REPLACE(fee_interest, ',', '') AS DECIMAL(18,2)) AS fee_interest,\n    TRY_CAST(REPLACE(tax, ',', '') AS DECIMAL(18,2)) AS tax,\n    TRY_CAST(REPLACE(balance, ',', '') AS DECIMAL(18,2)) AS balance,\n    row_number() over(order by file_source,record_group) AS record_sequence\nfrom transformed_data \norder by file_source, record_group \n)",
   "execution_count": null
  }
 ]
}